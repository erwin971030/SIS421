{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pregunta_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnYcyCd6vNr7",
        "outputId": "4557a953-ba19-4025-ebbe-06d582b15865"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Los bueyes y el eje de la carreta\\n\\nArrastraban unos bueyes una carreta cuyo eje chirriaba\\nruidosamente. Se volvieron aquellos a la carreta diciendo:\\n- Oye amiga, somos nosotros quienes llevamos la carga.\\n¿y eres tú quien se queja?\\n\\nEl águila y la flecha\\n\\nEstaba asentada un águila en el pico de un pe',\n",
              " 3451)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "f = open(\"/content/drive/MyDrive/2022 1/IA2/datasets/Cuentos.txt\", \"r\", encoding='utf-8')\n",
        "text = f.read()\n",
        "text[:300], len(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "all_characters = string.printable + \"ñÑáÁéÉíÍóÓúÚ¿¡\"\n",
        "all_characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "6mpxXAxQ2H6w",
        "outputId": "e93ab88c-8fed-4ceb-c66d-60f03a3698a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0cñÑáÁéÉíÍóÓúÚ¿¡'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "class Tokenizer(): \n",
        "    \n",
        "  def __init__(self):\n",
        "    self.all_characters = all_characters\n",
        "    self.n_characters = len(self.all_characters)\n",
        "    \n",
        "  def text_to_seq(self, string):\n",
        "    seq = []\n",
        "    for c in range(len(string)):\n",
        "        try:\n",
        "            seq.append(self.all_characters.index(string[c]))\n",
        "        except:\n",
        "            continue\n",
        "    return seq\n",
        "\n",
        "  def seq_to_text(self, seq):\n",
        "    text = ''\n",
        "    for c in range(len(seq)):\n",
        "        text += self.all_characters[seq[c]]\n",
        "    return text\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.n_characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jx8Dorz0Mfa",
        "outputId": "c8b2c14b-aeb8-4676-8988-95000ca36033"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.text_to_seq('El águila y l')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42Z3798O0JCx",
        "outputId": "62a6c5a1-1391-4790-e9d9-72767246d98b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40, 21, 94, 102, 16, 30, 18, 21, 10, 94, 34, 94, 21]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.seq_to_text([40, 21, 94, 102, 16, 30, 18, 21, 10, 94, 34, 94, 21])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ipRa2Eot2Yti",
        "outputId": "c995bd8a-bd88-4897-84fe-755045df2c08"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'El águila y l'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_encoded = tokenizer.text_to_seq(text)"
      ],
      "metadata": {
        "id": "NMPY7s1x2iyW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(text_encoded) * 80 // 100 \n",
        "train = text_encoded[:train_size]\n",
        "test = text_encoded[train_size:]\n",
        "\n",
        "len(train), len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPaOs0dA2lK_",
        "outputId": "c5f1b642-fb92-4ec8-cd3c-0c3f1165364f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2760, 691)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def windows(text, window_size = 50):\n",
        "    start_index = 0\n",
        "    end_index = len(text) - window_size\n",
        "    text_windows = []\n",
        "    while start_index < end_index:\n",
        "      text_windows.append(text[start_index:start_index+window_size+1])\n",
        "      start_index += 1\n",
        "    return text_windows\n",
        "\n",
        "text_encoded_windows = windows(text_encoded)"
      ],
      "metadata": {
        "id": "hJglaT4w3Q6z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.seq_to_text((text_encoded_windows[0])))\n",
        "print()\n",
        "print(tokenizer.seq_to_text((text_encoded_windows[1])))\n",
        "print()\n",
        "print(tokenizer.seq_to_text((text_encoded_windows[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T74v3ZLV3Tpb",
        "outputId": "ef6cf2fc-0773-49a3-c00a-c54b5aac9319"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los bueyes y el eje de la carreta\n",
            "\n",
            "Arrastraban unos\n",
            "\n",
            "os bueyes y el eje de la carreta\n",
            "\n",
            "Arrastraban unos \n",
            "\n",
            "s bueyes y el eje de la carreta\n",
            "\n",
            "Arrastraban unos b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class CharRNNDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, text_encoded_windows, train=True):\n",
        "    self.text = text_encoded_windows\n",
        "    self.train = train\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text)\n",
        "\n",
        "  def __getitem__(self, ix):\n",
        "    if self.train:\n",
        "      return torch.tensor(self.text[ix][:-1]), torch.tensor(self.text[ix][-1])\n",
        "    return torch.tensor(self.text[ix])"
      ],
      "metadata": {
        "id": "GtB79pRB3X_9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_encoded_windows = windows(train)\n",
        "test_text_encoded_windows = windows(test)\n",
        "\n",
        "dataset = {\n",
        "    'train': CharRNNDataset(train_text_encoded_windows),\n",
        "    'val': CharRNNDataset(test_text_encoded_windows)\n",
        "}\n",
        "\n",
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=64, shuffle=True, pin_memory=True),\n",
        "    'val': torch.utils.data.DataLoader(dataset['val'], batch_size=40, shuffle=False, pin_memory=True),\n",
        "}\n",
        "\n",
        "len(dataset['train']), len(dataset['val'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U-TpFF43bUX",
        "outputId": "e8d2db63-3865-4cef-9b99-ef793b1af8ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2710, 641)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input, output = dataset['train'][1]\n",
        "tokenizer.seq_to_text(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z8xqBLY-3ffK",
        "outputId": "0e7bc714-6322-49f7-f669-678520cabe24"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'os bueyes y el eje de la carreta\\n\\nArrastraban unos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.seq_to_text([output])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EhtfxueB3mtM",
        "outputId": "782230ae-8500-4681-d115-12a9b379fa6c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN(torch.nn.Module):\n",
        "  def __init__(self, input_size, embedding_size=100, hidden_size=256, num_layers=3, dropout=0.5):\n",
        "    super().__init__()\n",
        "    self.encoder = torch.nn.Embedding(input_size, embedding_size)\n",
        "    self.rnn = torch.nn.GRU(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "    self.fc = torch.nn.Linear(hidden_size, input_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x, h = self.rnn(x)         \n",
        "    y = self.fc(x[:,-1,:])\n",
        "    return y"
      ],
      "metadata": {
        "id": "p57p9gJY3o0C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CharRNN(input_size=tokenizer.n_characters)\n",
        "outputs = model(torch.randint(0, tokenizer.n_characters, (64, 50)))\n",
        "outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyvVvIok3vg5",
        "outputId": "ad19b1aa-22f3-495d-81b0-74326ffa7926"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 114])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def fit(model, dataloader, epochs=10):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f}\")\n",
        "        bar = tqdm(dataloader['val'])\n",
        "        val_loss = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f}\")\n",
        "\n",
        "def predict(model, X):\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        X = torch.tensor(X).to(device)\n",
        "        pred = model(X.unsqueeze(0))\n",
        "        return pred"
      ],
      "metadata": {
        "id": "Zyba_x6X3yzN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CharRNN(input_size=tokenizer.n_characters)\n",
        "fit(model, dataloader, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91gCwwip30Wr",
        "outputId": "443a897a-dc85-4782-d82e-5fd81cd68240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 3.33738: 100%|██████████| 43/43 [00:46<00:00,  1.09s/it]\n",
            "val_loss 3.19620: 100%|██████████| 17/17 [00:03<00:00,  4.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 loss 3.33738 val_loss 3.19620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 3.08459:  37%|███▋      | 16/43 [00:16<00:28,  1.04s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = \"El águila y la \"\n",
        "X_new_encoded = tokenizer.text_to_seq(X_new)\n",
        "y_pred = predict(model, X_new_encoded)\n",
        "y_pred = torch.argmax(y_pred, axis=1)[0].item()\n",
        "tokenizer.seq_to_text([y_pred])"
      ],
      "metadata": {
        "id": "wlSRc_LV4tlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "  X_new_encoded = tokenizer.text_to_seq(X_new[-100:])\n",
        "  y_pred = predict(model, X_new_encoded)\n",
        "  y_pred = torch.argmax(y_pred, axis=1)[0].item()\n",
        "  X_new += tokenizer.seq_to_text([y_pred])\n",
        "\n",
        "X_new"
      ],
      "metadata": {
        "id": "ZmqaMKgO4odq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}